{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing GMM models on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure 'train.ipynb' is run before running this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries to import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import pickle\n",
    "import per # Library to perform phoneme error recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accordingly change the mfcc_dir, TRAIN_DF, TEST_DF for the number of components and number of mfcc features\n",
    "\n",
    "mfcc_dir = 'models/mfcc_13_2/'\n",
    "TRAIN_DF = 'features/train1.hdf'\n",
    "TEST_DF = 'features/test1.hdf'\n",
    "ENERGY_FLAG = True # To include energy co-efficient or not\n",
    "TRAIN_FLAG = False # To perform training or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the hdf file got by generation from the import_timit.py file \n",
    "timit_test_df = pd.read_hdf(TEST_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8.432898672227827, -17.192751467628792, -26.4...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[8.174287614589556, -13.339226994007353, -24.3...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[8.081531888228382, -13.91009808149714, -18.14...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[8.01702587918423, -17.681371055083115, -21.71...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[7.951984723992553, -20.67793996977594, -26.00...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features labels\n",
       "0  [8.432898672227827, -17.192751467628792, -26.4...    sil\n",
       "1  [8.174287614589556, -13.339226994007353, -24.3...    sil\n",
       "2  [8.081531888228382, -13.91009808149714, -18.14...    sil\n",
       "3  [8.01702587918423, -17.681371055083115, -21.71...    sil\n",
       "4  [7.951984723992553, -20.67793996977594, -26.00...    sil"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first 5 rows of the table\n",
    "timit_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features and labels from the test set\n",
    "test_features = np.array(timit_test_df[\"features\"].tolist())\n",
    "test_labels = np.array(timit_test_df[\"labels\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451660, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting energy co-efficients from test file\n",
    "\n",
    "if not ENERGY_FLAG:\n",
    "    \n",
    "    rem = [0] # Change rem to [0], [0,12] or [0,12,24] for 13, 24 and 39 mfcc features respectively\n",
    "\n",
    "    for i in rem:\n",
    "        test_features = np.delete(test_features,i,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451660, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blank',\n",
       " 'aa',\n",
       " 'ae',\n",
       " 'ah',\n",
       " 'aw',\n",
       " 'ay',\n",
       " 'b',\n",
       " 'ch',\n",
       " 'd',\n",
       " 'dh',\n",
       " 'dx',\n",
       " 'eh',\n",
       " 'er',\n",
       " 'ey',\n",
       " 'f',\n",
       " 'g',\n",
       " 'hh',\n",
       " 'ih',\n",
       " 'iy',\n",
       " 'jh',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'ng',\n",
       " 'ow',\n",
       " 'oy',\n",
       " 'p',\n",
       " 'r',\n",
       " 's',\n",
       " 'sh',\n",
       " 'sil',\n",
       " 't',\n",
       " 'th',\n",
       " 'uh',\n",
       " 'uw',\n",
       " 'v',\n",
       " 'w',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing the blank phoneme label with the word 'blank'\n",
    "sortlabels = sorted(list(set(test_labels)))\n",
    "sortlabels[0] = 'blank'\n",
    "sortlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating array to store all models\n",
    "gmm_models=[]\n",
    "\n",
    "# Loading and storing all 40 models into array\n",
    "for i in sortlabels:\n",
    "    with open(mfcc_dir+i+'.pkl','rb') as pkl_file:\n",
    "        gmm_models.append(pickle.load(pkl_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Frame-level / Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP calculation for GMM model of phoneme  1 :  blank\n",
      "MAP calculation for GMM model of phoneme  2 :  aa\n",
      "MAP calculation for GMM model of phoneme  3 :  ae\n",
      "MAP calculation for GMM model of phoneme  4 :  ah\n",
      "MAP calculation for GMM model of phoneme  5 :  aw\n",
      "MAP calculation for GMM model of phoneme  6 :  ay\n",
      "MAP calculation for GMM model of phoneme  7 :  b\n",
      "MAP calculation for GMM model of phoneme  8 :  ch\n",
      "MAP calculation for GMM model of phoneme  9 :  d\n",
      "MAP calculation for GMM model of phoneme  10 :  dh\n",
      "MAP calculation for GMM model of phoneme  11 :  dx\n",
      "MAP calculation for GMM model of phoneme  12 :  eh\n",
      "MAP calculation for GMM model of phoneme  13 :  er\n",
      "MAP calculation for GMM model of phoneme  14 :  ey\n",
      "MAP calculation for GMM model of phoneme  15 :  f\n",
      "MAP calculation for GMM model of phoneme  16 :  g\n",
      "MAP calculation for GMM model of phoneme  17 :  hh\n",
      "MAP calculation for GMM model of phoneme  18 :  ih\n",
      "MAP calculation for GMM model of phoneme  19 :  iy\n",
      "MAP calculation for GMM model of phoneme  20 :  jh\n",
      "MAP calculation for GMM model of phoneme  21 :  k\n",
      "MAP calculation for GMM model of phoneme  22 :  l\n",
      "MAP calculation for GMM model of phoneme  23 :  m\n",
      "MAP calculation for GMM model of phoneme  24 :  n\n",
      "MAP calculation for GMM model of phoneme  25 :  ng\n",
      "MAP calculation for GMM model of phoneme  26 :  ow\n",
      "MAP calculation for GMM model of phoneme  27 :  oy\n",
      "MAP calculation for GMM model of phoneme  28 :  p\n",
      "MAP calculation for GMM model of phoneme  29 :  r\n",
      "MAP calculation for GMM model of phoneme  30 :  s\n",
      "MAP calculation for GMM model of phoneme  31 :  sh\n",
      "MAP calculation for GMM model of phoneme  32 :  sil\n",
      "MAP calculation for GMM model of phoneme  33 :  t\n",
      "MAP calculation for GMM model of phoneme  34 :  th\n",
      "MAP calculation for GMM model of phoneme  35 :  uh\n",
      "MAP calculation for GMM model of phoneme  36 :  uw\n",
      "MAP calculation for GMM model of phoneme  37 :  v\n",
      "MAP calculation for GMM model of phoneme  38 :  w\n",
      "MAP calculation for GMM model of phoneme  39 :  y\n",
      "MAP calculation for GMM model of phoneme  40 :  z\n"
     ]
    }
   ],
   "source": [
    "# Frame-level Accuracy (Testing Accuracy)\n",
    "test_scores=[]\n",
    "# MAP calculation for each of the 40 models. Finally an array of arrays is got\n",
    "for i in range(len(gmm_models)):\n",
    "    print(\"MAP calculation for GMM model of phoneme \",i+1,': ',sortlabels[i])\n",
    "    test_scores.append(gmm_models[i].score_samples(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame-level Accuracy:  11.619359695346057 %\n"
     ]
    }
   ],
   "source": [
    "# TESTING ACCURACY\n",
    "# Predicting labels using argmax indices\n",
    "pred_test_labels=np.array(sorted(list(set(test_labels))))[np.argmax((np.transpose(test_scores)),axis=1)]\n",
    "# Accuracy\n",
    "test_acc = (np.count_nonzero(pred_test_labels==test_labels)/len(test_labels))*100\n",
    "print(\"Frame-level Accuracy: \",test_acc,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme Error Rate:  90.55478929984393\n"
     ]
    }
   ],
   "source": [
    "# Phoneme error rate\n",
    "\n",
    "phoneme_error_rate = per.main(test_labels, pred_test_labels)\n",
    "\n",
    "print(\"Phoneme Error Rate: \",phoneme_error_rate*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF TESTING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
